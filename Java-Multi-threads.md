1. 什么是⾃旋锁？

   ⾃旋锁是SMP架构中的⼀种low-level的同步机制。
   1) <u>当线程A想要获取⼀把⾃旋锁⽽该锁⼜被其它线程锁持有时，线程A会在⼀个循环中⾃旋以检测锁是不是已经可⽤了。</u>
   2) ⾃选锁需要注意：
   由于⾃旋时不释放CPU，因⽽持有⾃旋锁的线程应该尽快释放⾃旋锁，否则等待该⾃旋锁的线程会⼀直在那⾥⾃旋，这就会浪费CPU时间。
   持有⾃旋锁的线程在sleep之前应该释放⾃旋锁以便其它线程可以获得⾃旋锁。
   3) ⽬前的JVM实现⾃旋会消耗CPU，如果⻓时间不调⽤doNotify()⽅法，doWait()⽅法会⼀直⾃旋，CPU会消耗太⼤
   4) <u>⾃旋锁⽐较适⽤于锁使⽤者保持锁时间⽐较短的情况，这种情况⾃旋锁的效率⽐较⾼</u>。
   5)⾃旋锁是⼀种对多处理器相当有效的机制，⽽<u>在单处理器⾮抢占式的系统中基本上没有作⽤</u>。
   
2.  什么是线程安全和线程不安全？

   **线程安全:** 就是多线程访问时，采⽤了加锁机制，当⼀个线程访问该类的某个数据时，进⾏保护，其他线程不能进⾏访问，直到该线程读取完，其他线程才可使⽤。不会出现数据不⼀致或者数据污染。

   **线程不安全**：就是不提供数据访问保护，有可能出现多个线程先后更改数据造成所得到的数据是脏数据线程安全问题都是由全局变量及静态变量引起的。
   若每个线程中对全局变量、静态变量只有读操作，⽽⽆写操作，⼀般来说，这个全局变量是线程安全的；若有多个线程同时执⾏写操作，⼀般都需要考虑线程同步，否则的话就可能影响线程安全。

3.  什么是CAS？

   1) CAS（compare and swap）的缩写，中⽂翻译成⽐较并交换。
   2) CAS 不通过JVM, 直接利⽤java本地⽅ JNI（Java Native Interface为JAVA本地调⽤）,直接调⽤CPU 的cmpxchg（是汇编指令）指令。
   3) 利⽤CPU的CAS指令，同时借助JNI来完成Java的⾮阻塞算法,实现原⼦操作。其它原⼦操作都是利⽤类似的特性完成
   的。
   **4) 整个java.util.concurrent都是建⽴在CAS之上的**，因此对于synchronized阻塞算法，J.U.C在性能上有了很⼤的提升。
   5) CAS是项乐观锁技术，当多个线程尝试使⽤CAS同时更新同⼀个变量时，只有其中⼀个线程能更新变量的值，⽽其它线程都失败，失败的线程并不会被挂起，⽽是被告知这次竞争中失败，并可以再次尝试。
   1) 使⽤CAS在线程冲突严重时，会⼤幅降低程序性能；**CAS只适合于线程冲突较少的情况使⽤**。
   2) synchronized在jdk1.6之后，已经改进优化。**synchronized的底层实现主要依靠Lock-Free的队列**，基本思路是**⾃旋后阻塞**，竞
   争切换后继续竞争锁，**稍微牺牲了公平性，但获得了⾼吞吐量**。在线程冲突较少的情况下，可以获得和CAS类似的性能；⽽线
   程冲突严重的情况下，性能远⾼于CAS。

4.  什么是乐观锁和悲观锁？

   **悲观锁:** Java在JDK1.5之前都是靠synchronized关键字保证同步的，这种通过使⽤⼀致的锁定协议来协调对共享状态的访问，可以**确保⽆论哪个线程持有共享变量的锁**，都采⽤独占的⽅式来访问这些变量。<u>独占锁其实就是⼀种悲观锁</u>，所以可以说synchronized是悲观锁。
   **乐观锁（ Optimistic Locking）**其实是⼀种思想。相对悲观锁⽽⾔，乐观锁假设认为数据⼀般情况下不会造成冲突，所以**在数据进⾏提交更新的时候，才会正式对数据的冲突与否进⾏检测**，如果发现冲突了，则让返回⽤户错误的信息，让⽤户决定如何去做。

5.  什么是AQS？

   AbstractQueuedSynchronizer 简称AQS，**是⼀个⽤于构建锁和同步容器的框架。**事实上**concurrent包内许多类都是基于AQS构建**，例如ReentrantLock，Semaphore，CountDownLatch，ReentrantReadWriteLock，FutureTask等。**AQS解决了在实现同步容器时设计的⼤量细节问题**。

   **AQS使⽤⼀个FIFO的队列表示排队等待锁的线程，队列头节点称作“哨兵节点”或者“哑节点”，它不与任何线程关联。其他的节点与等待线程关联，每个节点维护⼀个等待状态waitStatus。**

6.  什么是原⼦操作？在Java Concurrency API中有哪些原⼦类(atomic classes)？
   1) **原⼦操作是指⼀个不受其他操作影响的操作任务单元。**原⼦操作是在多线程环境下避免数据不⼀致必须的⼿段。
   2) int++并不是⼀个原⼦操作，所以当⼀个线程读取它的值并加1时，另外⼀个线程有可能会读到之前的值，这就会引发错误。
   3) 为了解决这个问题，必须保证增加操作是原⼦的，在JDK1.5之前我们可以使⽤同步技术来做到这⼀点。到JDK1.5，java.util.concurrent.atomic包提供了int和long类型的装类，它们可以⾃动的保证对于他们的操作是原⼦的并且不需要使⽤同步。

7.  什么是Executors框架？

   Java通过Executors提供四种线程池，分别为：
   1) newCachedThreadPool创建⼀个可缓存线程池，如果线程池⻓度超过处理需要，可灵活回收空闲线程，若⽆可回收，则新建线程。
   2) newFixedThreadPool 创建⼀个定⻓线程池，可控制线程最⼤并发数，超出的线程会在队列中等待。
   3) newScheduledThreadPool 创建⼀个定⻓线程池，⽀持定时及周期性任务执⾏。
   4) newSingleThreadExecutor 创建⼀个单线程化的线程池，它只会⽤唯⼀的⼯作线程来执⾏任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执⾏。

8.  什么是阻塞队列？如何使⽤阻塞队列来实现⽣产者-消费者模型？

   1) JDK7提供了7个阻塞队列。（也属于并发容器）
   i. ArrayBlockingQueue ：⼀个由数组结构组成的有界阻塞队列。
   ii. LinkedBlockingQueue ：⼀个由链表结构组成的有界阻塞队列。
   iii. PriorityBlockingQueue ：⼀个⽀持优先级排序的⽆界阻塞队列。
   iv. DelayQueue：⼀个使⽤优先级队列实现的⽆界阻塞队列。
   v. SynchronousQueue：⼀个不存储元素的阻塞队列。
   vi. LinkedTransferQueue：⼀个由链表结构组成的⽆界阻塞队列。
   vii. LinkedBlockingDeque：⼀个由链表结构组成的双向阻塞队列。
   2) 概念：阻塞队列是⼀个在队列基础上有又⽀持了两个附加操作的队列。
   3)  2个附加操作：
   **⽀持阻塞的插⼊⽅法：队列满时，队列会阻塞插⼊元素的线程，直到队列不满。**
   **⽀持阻塞的移除⽅法：队列空时，获取元素的线程会等待队列变为⾮空。**

9.  什么是Callable和Future?
   1) Callable 和 Future 是⽐较有趣的⼀对组合。当我们需要**获取线程的执⾏结果**时，就需要⽤到它们。**Callable⽤于产⽣结果，Future⽤于获取结果。**
   2) Callable接⼝使⽤泛型去定义它的返回类型。Executors类提供了⼀些有⽤的⽅法去在线程池中执⾏Callable内的任务。由于Callable任务是并⾏的，必须等待它返回的结果。java.util.concurrent.Future对象解决了这个问题。
   3) **在线程池提交Callable任务后返回了⼀个Future对象**，使⽤它可以知道Callable任务的状态和得到Callable返回的执⾏结果。Future提供了get()⽅法，等待Callable结束并获取它的执⾏结果。

10.  什么是FutureTask?
    1） **FutureTask可⽤于异步获取执⾏结果或取消执⾏任务的场景**。通过传⼊Runnable或者Callable的任务给FutureTask，直接调⽤其run⽅法或者放⼊线程池执⾏，之后可以在外部通过FutureTask的get⽅法异步获取执⾏结果，因此，**FutureTask⾮常适合⽤于耗时的计算，主线程可以在完成⾃⼰的任务后，再去获取结果**。另外，FutureTask还可以确保即使调⽤了多次run⽅法，它都只会执⾏⼀次Runnable或者Callable任务，或者通过cancel取消FutureTask的执⾏等。
    2） futuretask可⽤于执⾏多任务、以及避免⾼并发情况下多次创建数据机锁的出现。

11.  什么是同步容器和并发容器的实现？
    1) 同步容器
    a. 主要代表有Vector和Hashtable，以及Collections.synchronizedXxx等。
    b. 锁的粒度为当前对象整体。
    c. 迭代器是及时失败的，即在迭代的过程中发现被修改，就会抛出ConcurrentModificationException。
    2、并发容器
    a. 主要代表有ConcurrentHashMap、CopyOnWriteArrayList、ConcurrentSkipListMap、ConcurrentSkipListSet。
    b. 锁的粒度是分散的、细粒度的，即**读和写是使⽤不同的锁。**
    c. 迭代器具有弱⼀致性，即可以容忍并发修改，不会抛出ConcurrentModificationException。

    ConcurrentHashMap: 采⽤分段锁技术，同步容器中，是⼀个容器⼀个锁，但在ConcurrentHashMap中，会将hash表的数组部分分成若⼲段，每段维护⼀个锁，以达到⾼效的并发访问；

12.  什么是多线程的上下⽂切换？

    1) 多线程：是指从软件或者硬件上实现多个线程的并发技术。
    2) 多线程的好处：
    i. 使⽤多线程可以把程序中占据时间⻓的任务放到后台去处理，如图⽚、视屏的下载
    ii. 发挥多核处理器的优势，并发执⾏让系统运⾏的更快、更流畅，⽤户体验更好
    3) 多线程的缺点：

    i. ⼤量的线程降低代码的可读性；

    ii. 更多的线程需要更多的内存空间;

    iii. 当多个线程对同⼀个资源出现争夺时候要注意线程安全的问题。
    4) 多线程的上下⽂切换：
    **CPU通过时间⽚分配算法来循环执⾏任务，当前任务执⾏⼀个时间⽚后会切换到下⼀个任务。但是，在切换前会保存上⼀个任务的状态，以便下次切换回这个任务时，可以再次加载这个任务的状态**.

13.  ThreadLocal的设计理念与作⽤？
    1) Java中的ThreadLocal类**允许创建只能被同⼀个线程读写的变量**。因此，如果⼀段代码含有⼀个ThreadLocal变量的引⽤，即使两个线程同时执⾏这段代码，它们也⽆法访问到对⽅的ThreadLocal变量。
        a. 概念：线程局部变量。在并发编程的时候，成员变量如果不做任何处理其实是线程不安全的，各个线程都在操作同⼀个变量，显
    然是不⾏的，并且我们也知道volatile这个关键字也是不能保证线程安全的。那么在有⼀种情况之下，我们需要满⾜这样⼀个条件：

    **变量是同⼀个，但是每个线程都使⽤同⼀个初始值，也就是使⽤同⼀个变量的⼀个新的副本**。这种情况之下ThreadLocal就⾮常适⽤，⽐如说DAO的数据库连接，我们知道DAO是单例的，那么他的属性Connection就不是⼀个线程安全的变量。⽽我们每个线程都需要使⽤他，并且各⾃使⽤各⾃的。这种情况，ThreadLocal就⽐较好的解决了这个问题。
        b. 原理：从本质来讲，就是每个线程都维护了⼀个map，⽽这个map的key就是threadLocal，⽽值就是我们set的那个值，每次线程在get的时候，都从⾃⼰的变量中取值，既然从⾃⼰的变量中取值，那肯定就不存在线程安全问题，总体来讲，ThreadLocal这个变量的状态根本没有发⽣变化，他仅仅是**充当⼀个key的⻆⾊，另外提供给每⼀个线程⼀个初始值**。
       c. 实现机制：**每个Thread对象内部都维护了⼀个ThreadLocalMap这样⼀个ThreadLocal.**

    `/* ThreadLocal values pertaining to this thread. This map is maintained`

    `by the ThreadLocal class. */`
    `ThreadLocal.ThreadLocalMap threadLocals = null;`

       d. 应⽤场景：当很多线程需要多次使⽤同⼀个对象，并且需要该对象具有相同初始化值的时候最适合使⽤ThreadLocal。

14.  ThreadPool（线程池）⽤法与优势？

    1) ThreadPool 优点
    a. **减少了创建和销毁线程的次数**，每个⼯作线程都可以被重复利⽤，**可执⾏多个任务**
    b. 可以根据系统的承受能⼒，调整线程池中⼯作线线程的数⽬，防⽌因为因为消耗过多的内存，⽽把服务器累趴下(每个线程需要⼤约1MB内存，线程开的越多，消耗的内存也就越⼤，最后死机)
        i. 减少在创建和销毁线程上所花的时间以及系统资源的开销;
        ii. 如不使⽤线程池，有可能造成系统创建⼤量线程⽽导致消耗完系统内存;

    2) ⽐较重要的⼏个类：

    | 类                          | 描述                                                         |
    | --------------------------- | ------------------------------------------------------------ |
    | ExecutorService             | 真正的线程池接⼝。                                           |
    | ScheduledExecutorService    | 能和Timer/TimerTask类似，解决那些需要任务重复执⾏的问题。    |
    | ScheduledThreadPoolExecutor | 继承ThreadPoolExecutor的ScheduledExecutorService接⼝实现，周期性任务调度的类实现。 |
    | ThreadPoolExecutor          | ExecutorService的默认实现。                                  |

    3) 任务执⾏顺序

    i. 当线程数⼩于corePoolSize时，创建线程执⾏任务。
    ii. 当线程数⼤于等于corePoolSize并且workQueue没有满时，放⼊workQueue中
    iii. 线程数⼤于等于corePoolSize并且当workQueue满时，新任务新建线程运⾏，线程总数要⼩于maximumPoolSize
    iv. 当线程总数等于maximumPoolSize并且workQueue满了的时候执⾏handler的rejectedExecution。也就是拒绝策略。

15.  **synchronized和ReentrantLock的区别？**

    1) 基础知识
         a. 可重⼊锁。**可重⼊锁是指同⼀个线程可以多次获取同⼀把锁**。ReentrantLock和synchronized都是可重⼊锁。
         b. 可中断锁。可中断锁是指线程尝试获取锁的过程中，是否可以响应中断。**synchronized是不可中断锁，⽽ReentrantLock则提供了中断功能。**
         c. 公平锁与⾮公平锁。**公平锁是指多个线程同时尝试获取同⼀把锁时，获取锁的顺序按照线程达到的顺序**，⽽⾮公平锁则允许线程“插队”。synchronized是⾮公平锁，⽽ReentrantLock的默认实现是⾮公平锁，但是也可以设置为公平锁。
         d. CAS操作(CompareAndSwap)。CAS操作简单的说就是⽐较并交换。CAS 操作包含三个操作数 —— 内存位置（V）、预期原值（A）和新值(B)。如果内存位置的值与预期原值相匹配，那么处理器会⾃动将该位置值更新为新值。否则，处理器不做任何操作。⽆论哪种情况，它都会在 CAS 指令之前返回该位置的值。CAS 有效地说明了“我认为位置 V 应该包含值 A；如果包含该值，则将 B 放到这个位置；否则，不要更改该位置，只告诉我这个位置现在的值即可。”<!--和这个问题有关系吗。。。-->
    2) Synchronized
         a. **synchronized是java内置的关键字，它提供了⼀种独占的加锁⽅式**。synchronized的获取和释放锁由JVM实现，⽤户不需要显示的释放锁，⾮常⽅便。然⽽synchronized也有⼀定的局限性：

    ​       i. 当线程尝试获取锁的时候，如果获取不到锁会⼀直阻塞。

    ​       ii.如果获取锁的线程进⼊休眠或者阻塞，除⾮当前线程异常，否则其他线程尝试获取锁必须⼀直等待。
    3) ReentrantLock
    ​    a.  ReentrantLock它是JDK 1.5之后提供的API层⾯的互斥锁，需要lock()和unlock()⽅法配合try/finally语句块来完成。
    ​    b. 等待可中断避免，出现死锁的情况（如果别的线程正持有锁，会等待参数给定的时间，在等待的过程中，如果获取了锁定，就返回true，如果等待超时，返回false）
    ​    c. 公平锁与⾮公平锁多个线程等待同⼀个锁时，必须按照申请锁的时间顺序获得锁，Synchronized锁⾮公平锁，ReentrantLock默认的构造函数是创建的⾮公平锁，可以通过参数true设为公平锁，但公平锁表现的性能不是很好。

16.  Java Concurrency API中的Lock接⼝(Lock interface)是什么？对⽐同步它有什么优势？

    1) Lock接⼝⽐同步⽅法和同步块提供了更具扩展性的锁操作。他们允许更灵活的结构，可以具有完全不同的性质，并且可以⽀持多个相关类的条件对象。
    2) 它的优势有：
    a. 可以使锁更公平;

    b. 可以使线程在等待锁的时候响应中断;
    c. 可以让线程尝试获取锁，并在⽆法获取锁的时候⽴即返回或者等待⼀段时间;
    d. 可以在不同的范围，以不同的顺序获取和释放锁;

17.  **ConcurrentHashMap的并发度是什么？**

    1) ⼯作机制（分⽚思想）：它引⼊了⼀个“分段锁”的概念，具体可以理解为把⼀个⼤的Map拆分成N个⼩的segment，根据key.hashCode()来决定把key放到哪个HashTable中。可以提供相同的线程安全，但是效率提升N倍，默认提升16倍。
    2) 应⽤：当读>写时使⽤，适合做缓存，在程序启动时初始化，之后可以被多个线程访问；
    3) hash冲突：
          a. 简介：HashMap中调⽤hashCode()⽅法来计算hashCode。由于在Java中两个不同的对象可能有⼀样的hashCode,所以不同的键可能有⼀样hashCode，从⽽导致冲突的产⽣。
           b. hash冲突解决：**使⽤平衡树来代替链表**，当同⼀hash中的元素数量超过特定的值便会由链表切换到平衡树.
    4) ⽆锁读：ConcurrentHashMap之所以有较好的并发性是因为ConcurrentHashMap是**⽆锁读和加锁写**，并且**利⽤了分段锁**（不是在所有的entry上加锁，⽽是在⼀部分entry上加锁）；

    读之前会先判断count(jdk1.6)，其中的count是被volatile修饰的(当变量被volatile修饰后，每次更改该变量的时候会将更改结果写到系统主内存中，利⽤多处理器的缓存⼀致性，其他处理器会发现⾃⼰的缓存⾏对应的内存地址被修改，就会将⾃⼰处理器的缓存⾏设置为失效，并强制从系统主内存获取最新的数据。)，故可以实现⽆锁读。
    5) ConcurrentHashMap的并发度就是segment的⼤⼩，默认为16，这意味着最多同时可以有16条线程操作ConcurrentHashMap，这也是ConcurrentHashMap对Hashtable的最⼤优势。

18.  ReentrantReadWriteLock读写锁的使⽤？

    1) 读写锁：分为读锁和写锁，**多个读锁不互斥，读锁与写锁互斥**，这是由jvm⾃⼰控制的，你只要上好相应的锁即可。
    2) 如果你的代码只读数据，可以很多⼈同时读，但不能同时写，那就上读锁；
    3) 如果你的代码修改数据，只能有⼀个⼈在写，且不能同时读取，那就上写锁。总之，**读的时候上读锁，写的时候上写锁**！

19.  Condition接⼝及其实现原理?

    1) 在java.util.concurrent包中，有两个很特殊的⼯具类，Condition和ReentrantLock，使⽤过的⼈都知道，ReentrantLock（重⼊锁）是jdk的concurrent包提供的⼀种独占锁的实现.

    2) 我们知道在线程的同步时可以使⼀个线程阻塞⽽等待⼀个信号，同时放弃锁使其他线程可以能竞争到锁

    3) 在synchronized中我们可以使⽤Object的wait()和notify⽅法实现这种等待和唤醒

    4) 但是在Lock中怎么实现这种wait和notify呢？答案是Condition，学习Condition主要是为了⽅便以后学习blockqueue和concurrenthashmap的源码，同时也进⼀步理解ReentrantLock。

20.  Fork/Join框架的理解?
    1) Fork就是把⼀个⼤任务切分为若⼲⼦任务并⾏的执⾏。
    2) Join就是合并这些⼦任务的执⾏结果，最后得到这个⼤任务的结果.

21.  wait()和sleep()的区别?

    1) sleep(): **是线程类（Thread）的静态⽅法，让调⽤线程进⼊睡眠状态**，让出执⾏机会给其他线程，等到休眠时间结束后，线程进⼊就绪状态和其他线程⼀起竞争cpu的执⾏时间。
    因为sleep() 是static静态的⽅法，他不能改变对象的机锁，当⼀个synchronized块中调⽤了sleep() ⽅法，线程虽然进⼊休眠，但是对象的机锁没有被释放，**其他线程依然⽆法访问这个对象。**
    2) wait(): wait()是Object类的⽅法，当⼀个线程执⾏到wait⽅法时，它就进⼊到⼀个和该对象相关的等待池，**同时释放对象的机锁**，使得其他线程能够访问，可以通过notify，notifyAll⽅法来唤醒等待的线程.

22.  线程的五个状态（五种状态，创建、就绪、运⾏、阻塞和死亡）?

    线程通常都有五种状态，创建、就绪、运⾏、阻塞和死亡。
    i. 第⼀是创建状态。在⽣成线程对象，并没有调⽤该对象的start⽅法，这是线程处于创建状态。
    ii. 第⼆是就绪状态。当调⽤了线程对象的start⽅法之后，该线程就进⼊了就绪状态，但是此时线程调度程序还没有把该线程设置为当前线程，此时处于就绪状态。在线程运⾏之后，从等待或者睡眠中回来之后，也会处于就绪状态。
    iii. 第三是运⾏状态。线程调度程序将处于就绪状态的线程设置为当前线程，此时线程就进⼊了运⾏状态，开始运⾏run函数当中的代码。
    iv. 第四是阻塞状态。线程正在运⾏的时候，被暂停，通常是为了等待某个时间的发⽣(⽐如说某项资源就绪)之后再继续运⾏。sleep,suspend，wait等⽅法都可以导致线程阻塞。
    v. 第五是死亡状态。如果⼀个线程的run⽅法执⾏结束或者调⽤stop⽅法后，该线程就会死亡。对于已经死亡的线程，⽆法再使⽤start⽅法令其进⼊就绪。

23.  start()⽅法和run()⽅法的区别？

    1) start()⽅法来启动⼀个线程，真正实现了多线程运⾏。
    2) 如果直接调⽤run(),其实就相当于是调⽤了⼀个普通函数⽽已，直接调⽤run()⽅法必须等待run()⽅法执⾏完毕才能执⾏下⾯的代码，所以执⾏路径还是只有⼀条，根本就没有线程的特征，所以在多线程执⾏时要使⽤start()⽅法⽽不是run()⽅法。

24.  Runnable接⼝和Callable接⼝的区别？

    1)Runnable接⼝中的run()⽅法的返回值是void，它做的事情只是纯粹地去执⾏run()⽅法中的代码⽽已；

    2) Callable接⼝中的call()⽅法是有返回值的，是⼀个泛型，**和Future、FutureTask配合可以⽤来获取异步执⾏的结果**。

25.  volatile关键字的作⽤？

    1) **多线程主要围绕可⻅性和原⼦性两个特性⽽展开**，使⽤volatile关键字修饰的变量，保证了其在多线程之间的可⻅性，即每次读取到volatile变量，⼀定是最新的数据。

    2) 代码底层执⾏不像我们看到的⾼级语⾔—-Java程序这么简单，它的执⾏是Java代码–>字节码–>根据字节码执⾏对应的C/C++代码–>C/C++代码被编译成汇编语⾔–>和硬件电路交互，现实中，为了获取更好的性能JVM可能会对指令进⾏重排序，多线程下可能会出现⼀些意想不到的问题。使⽤volatile则会对禁⽌语义重排序，当然这也⼀定程度上降低了代码执⾏效率。
    
26.  Java中如何获取到线程dump⽂件？
    死循环、死锁、阻塞、⻚⾯打开慢等问题，查看线程dump是最好的解决问题的途径。所谓线程dump也就是线程堆栈，
    获取到线程堆栈有两步：
    1）获取到线程的pid，可以通过使⽤jps命令，在Linux环境下还可以使⽤ps -ef | grep java
    2）打印线程堆栈，可以通过使⽤jstack pid命令，在Linux环境下还可以使⽤kill -3 pid
    3）另外提⼀点，Thread类提供了⼀个getStackTrace()⽅法也可以⽤于获取线程堆栈。这是⼀个实例⽅法，因此此⽅法是和具体线程实例绑定的，每次获取到的是具体某个线程当前运⾏的堆栈。

27.  线程和进程有什么区别？

    1） 进程是系统进⾏资源分配的基本单位，有独⽴的内存地址空间

    2） 线程是CPU独⽴运⾏和独⽴调度的基本单位，没有单独地址空间，有独⽴的栈，局部变量，寄存器， 程序计数器等。

    3） 创建进程的开销⼤，包括创建虚拟地址空间等需要⼤量系统资源

    4）创建线程开销⼩，基本上只有⼀个内核对象和⼀个堆栈。

    5）⼀个进程⽆法直接访问另⼀个进程的资源；同⼀进程内的多个线程共享进程的资源。

    6） 进程切换开销⼤，线程切换开销⼩；进程间通信开销⼤，线程间通信开销⼩。

    7） 线程属于进程，不能独⽴执⾏。每个进程⾄少要有⼀个线程，成为主线程

28.  线程实现的⽅式有⼏种（四种）？

    1) 继承Thread类，重写run⽅法

    2) 实现Runnable接⼝，重写run⽅法，实现Runnable接⼝的实现类的实例对象作为Thread构造函数的target

    3) 实现Callable接⼝通过FutureTask包装器来创建Thread线程

    4) 通过线程池创建线程

29.  ⾼并发、任务执⾏时间短的业务怎样使⽤线程池？并发不⾼、任务执⾏时间⻓的业务怎样使⽤线程池？并发⾼、业务执⾏时间⻓的业务怎样使⽤线程池？

    1） ⾼并发、任务执⾏时间短的业务：线程池线程数可以设置为CPU核数+1，减少线程上下⽂的切换。

    2） 并发不⾼、任务执⾏时间⻓的业务要区分开看：
    a. 假如是业务时间⻓集中在IO操作上，也就是IO密集型的任务，因为IO操作并不占⽤CPU，所以不要让所有的CPU闲下来，可以加⼤线程池中的线程数⽬，让CPU处理更多的业务
    b. 假如是业务时间⻓集中在计算操作上，也就是计算密集型任务，这个就没办法了，和（1）⼀样吧，线程池中的线程数设置得少⼀些，减少线程上下⽂的切换

    3） 并发⾼、业务执⾏时间⻓，解决这种类型任务的关键不在于线程池⽽在于整体架构的设计，看看这些业务⾥⾯某些数据是否能做缓存是第⼀步，增加服务器是第⼆步，⾄于线程池的设置，设置参考（2）。最后，业务执⾏时间⻓的问题，也可能需要分析⼀下，看看能不能使⽤中间件对任务进⾏拆分和解耦。

30.  如果你提交任务时，线程池队列已满，这时会发⽣什么？
    1) 如果你使⽤的LinkedBlockingQueue，也就是⽆界队列的话，没关系，继续添加任务到阻塞队列中等待执⾏，因为LinkedBlockingQueue可以近乎认为是⼀个⽆穷⼤的队列，可以⽆限存放任务；
    2) 如果你使⽤的是有界队列⽐⽅说ArrayBlockingQueue的话，任务⾸先会被添加到ArrayBlockingQueue中，ArrayBlockingQueue满了，则会使⽤拒绝策略RejectedExecutionHandler处理满了的任务，默认是AbortPolicy。

31.  锁的等级：⽅法锁、对象锁、类锁?

    1) ⽅法锁（synchronized修饰⽅法时）
    a. 通过在⽅法声明中加⼊ synchronized关键字来声明 synchronized ⽅法。
    b. synchronized ⽅法控制对类成员变量的访问： 
    c. 每个类实例对应⼀把锁，每个 synchronized ⽅法都必须获得调⽤该⽅法的类实例的锁⽅能执⾏，否则所属线程阻塞，⽅法⼀旦执⾏，就独占该锁，直到从该⽅法返回时才将锁释放，此后被阻塞的线程⽅能获得该锁，重新进⼊可执⾏状态。这种机制确保了同⼀时刻对于每⼀个类实例，其所有声明为 synchronized 的成员函数中⾄多只有⼀个处于可执⾏状态，从⽽有效避免了类成员变量的访问冲突。

    2) 对象锁（synchronized修饰⽅法或代码块）
    a. 当⼀个对象中有synchronized method或synchronized block的时候调⽤此对象的同步⽅法或进⼊其同步区域时，
    就必须先获得对象锁。如果此对象的对象锁已被其他调⽤者占⽤，则需要等待此锁被释放。（⽅法锁也是对象锁） 

    b. java的所有对象都含有1个互斥锁，这个锁由JVM⾃动获取和释放。线程进⼊synchronized⽅法的时候获取该对象的锁，当然如果已经有线程获取了这个对象的锁，那么当前线程会等待；synchronized⽅法正常返回或者抛异常⽽终⽌，JVM会⾃动释放对象锁。这⾥也体现了⽤synchronized来加锁的1个好处，⽅法抛异常的时候，锁仍然可以由JVM来⾃动释放。　

    3) 类锁(synchronized 修饰静态的⽅法或代码块)
    a. 由于⼀个class不论被实例化多少次，其中的静态⽅法和静态变量在内存中都只有⼀份。所以，⼀旦⼀个静态的⽅法被申明为synchronized。此类所有的实例化对象在调⽤此⽅法，共⽤同⼀把锁，我们称之为类锁。 

    4) **对象锁是⽤来控制实例⽅法之间的同步，类锁是⽤来控制静态⽅法（或静态变量互斥体）之间的同步**

32.  如果同步块内的线程抛出异常会发⽣什么？

    synchronized⽅法正常返回或者抛异常⽽终⽌，JVM会⾃动释放对象锁

33.  ⼀个线程如果出现了运⾏时异常会怎么样?

    1) 如果这个异常没有被捕获的话，这个线程就停⽌执⾏了。

    2) 另外重要的⼀点是：如果这个线程持有某个对象的监视器，那么这个对象监视器会被⽴即释放.

34.  如何在两个线程之间共享数据?
    **通过在线程之间共享对象就可以了**，然后通过wait/notify/notifyAll、await/signal/signalAll进⾏唤起和等待，⽐⽅说阻塞队列BlockingQueue就是为线程之间共享数据⽽设计的。

35.  并发编程（concurrency）并⾏编程（parallellism）有什么区别？

    1) 解释⼀：并⾏是指两个或者多个事件在同⼀时刻发⽣；⽽并发是指两个或多个事件在同⼀时间间隔发⽣。

    2) 解释⼆：并⾏是在不同实体上的多个事件，并发是在同⼀实体上的多个事件。

    3) 解释三：在⼀台处理器上“同时”处理多个任务，在多台处理器上同时处理多个任务。如hadoop分布式集群所以并发编程的⽬标是充分的利⽤处理器的每⼀个核，以达到最⾼的处理性能。

36.  ⽣产者消费者模型的作⽤是什么?

    1) 通过平衡⽣产者的⽣产能⼒和消费者的消费能⼒来**提升整个系统的运⾏效率**，这是⽣产者消费者模型最重要的作⽤。

    2) **解耦**，这是⽣产者消费者模型附带的作⽤，解耦意味着⽣产者和消费者之间的联系少，联系越少越可以独⾃发展⽽不需要受到相互的制约。

37.  Java中⽤到的线程调度算法是什么

    抢占式。⼀个线程⽤完CPU之后，操作系统会根据线程优先级、线程饥饿情况等数据算出⼀个总的优先级并分配下⼀个时间⽚给某个线程执⾏。

38.  单例模式的线程安全性?
    ⾸先要说的是单例模式的线程安全意味着：<u>某个类的实例在多线程环境下只会被创建⼀次出来</u>。单例模式有很多种的写法，我总结⼀下：
    （1）饿汉式单例模式的写法：线程安全
    （2）懒汉式单例模式的写法：⾮线程安全
    （3）双检锁单例模式的写法：线程安全

39.  线程类的构造⽅法、静态块是被哪个线程调⽤的?
    线程类的构造⽅法、静态块是被new这个线程类所在的线程所调⽤的，⽽run⽅法⾥⾯的代码才是被线程⾃身所调⽤的。

40.  同步⽅法和同步块，哪个是更好的选择?

    **同步块是更好的选择，因为它不会锁住整个对象**（当然也可以让它锁住整个对象）。同步⽅法会锁住整个对象，哪怕这个类中有多个不相关联的同步块，这通常会导致他们停⽌执⾏并需要等待获得这个对象上的锁。
    synchronized(this)以及⾮static的synchronized⽅法（⾄于static synchronized⽅法请往下看），只能防⽌多个线程同时执⾏同⼀个对象的同步代码段。
    如果要锁住多个对象⽅法，可以锁住⼀个固定的对象，或者锁住这个类的Class对象。
    **synchronized锁住的是括号⾥的对象，⽽不是代码。对于⾮static的synchronized⽅法，锁的就是对象本身也就是this。**

41.  **如何检测死锁？怎么预防死锁？**
    1. 概念：
    是指两个或两个以上的进程在执⾏过程中，因争夺资源⽽造成的⼀种互相等待的现象，若⽆外⼒作⽤，它们都将⽆法推进下去。此时称系统处于死锁；
    2. 死锁的四个必要条件：
    i. **互斥条件**：进程对所分配到的资源不允许其他进程进⾏访问，若其他进程访问该资源，只能等待，直⾄占有该资源的进程使⽤完成后释放该资源
    ii. **请求和保持条件**：进程获得⼀定的资源之后，⼜对其他资源发出请求，但是该资源可能被其他进程占有，此时请求阻塞，但⼜对⾃⼰获得的资源保持不放
    iii. **不可剥夺条件**：是指进程已获得的资源，在未完成使⽤之前，不可被剥夺，只能在使⽤完后⾃⼰释放
    iv. **环路等待条件**：是指进程发⽣死锁后，若⼲进程之间形成⼀种头尾相接的循环等待资源关系
    2. 死锁产⽣的原因：
    1.因竞争资源发⽣死锁 现象：系统中供多个进程共享的资源的数⽬不⾜以满⾜全部进程的需要时，就会引起对诸资源的竞争⽽发⽣死锁现象
    2.进程推进顺序不当发⽣死锁
    3. 检查死锁
    i. 有两个容器，⼀个⽤于保存线程正在请求的锁，⼀个⽤于保存线程已经持有的锁。每次加锁之前都会做如下检测:
    ii. 检测当前正在请求的锁是否已经被其它线程持有,如果有，则把那些线程找出来
    iii. 遍历第⼀步中返回的线程，检查⾃⼰持有的锁是否正被其中任何⼀个线程请求，如果第⼆步返回真,表示出现了死锁
    4. 死锁的解除与预防：控制不要让四个必要条件成⽴。

42.  可以运⾏时kill掉⼀个线程吗？
    a. 不可以，线程有5种状态，新建（new）、可运⾏（runnable）、运⾏中（running）、阻塞（block）、死亡（dead）。
    b. 只有当线程run⽅法或者主线程main⽅法结束，⼜或者抛出异常时，线程才会结束⽣命周期。

43.  关于synchronized：

    1) 在某个对象的所有synchronized⽅法中,在某个时刻只能有⼀个唯⼀的⼀个线程去访问这些synchronized⽅法

    2) 如果⼀个⽅法是synchronized⽅法,那么该synchronized关键字表示给当前对象上锁(即this)相当于synchronized(this){}

    3) 如果⼀个synchronized⽅法是static的,那么该synchronized表示给当前对象所对应的class对象上锁(每个类不管⽣成多少对象,其对应的class对象只有⼀个)

44.  spring单例为什么没有安全问题(ThreadLocal)

    1) ThreadLocal：spring使⽤ThreadLocal解决线程安全问题；ThreadLocal会为每⼀个线程提供⼀个独⽴的变量副本，从⽽隔离了多个线程对数据的访问冲突。因为每⼀个线程都拥有⾃⼰的变量副本，从⽽也就没有必要对该变量进⾏同步了。ThreadLocal提供了线程安全的共享对象，在编写多线程代码时，可以把不安全的变量封装进ThreadLocal。概括起来说，对于多线程资源共享的问题，同步机制采⽤了“以时间换空间”的⽅式，⽽ThreadLocal采⽤了“以空间换时间”的⽅式。前者仅提供⼀份变量，让不同的线程排队访问，⽽后者为每⼀个线程都提供了⼀份变量，因此可以同时访问⽽互不影响。在很多情况下，ThreadLocal⽐直接使⽤synchronized同步机制解决线程安全问题更简单，更⽅便，且结果程序拥有更⾼的并发性。
    2) 单例：⽆状态的Bean(⽆状态就是⼀次操作，不能保存数据。⽆状态对象(Stateless Bean)，就是没有实例变量的对象，不能保存数据，是不变类，是线程安全的。)适合⽤不变模式，技术就是单例模式，这样可以共享实例，提⾼性能。

45.  线程池原理：

     1） 使⽤场景：假设⼀个服务器完成⼀项任务所需时间为：T1-创建线程时间，T2-在线程中执⾏任务的时间，T3-销毁线程时间。
    如果T1+T3远⼤于T2，则可以使⽤线程池，以提⾼服务器性能；
     2） 组成：
            1、线程池管理器（ThreadPool）：⽤于创建并管理线程池，包括 创建线程池，销毁线程池，添加新任务；
            2、⼯作线程（PoolWorker）：线程池中线程，在没有任务时处于等待状态，可以循环的执⾏任务；
            3、任务接⼝（Task）：每个任务必须实现的接⼝，以供⼯作线程调度任务的执⾏，它主要规定了任务的⼊⼝，任务执⾏完后
    的收尾⼯作，任务的执⾏状态等；
            4、任务队列（taskQueue）：⽤于存放没有处理的任务。提供⼀种缓冲机制。
     3）原理：线程池技术正是关注如何缩短或调整T1,T3时间的技术，从⽽提⾼服务器程序性能的。它把T1，T3分别安排在服务器程
    序的启动和结束的时间段或者⼀些空闲的时间段，这样在服务器程序处理客户请求时，不会有T1，T3的开销了。    

    4）⼯作流程：
            a、线程池刚创建时，⾥⾯没有⼀个线程(也可以设置参数prestartAllCoreThreads启动预期数量主线程)。任务队列是作为参数传进来的。不过，就算队列⾥⾯有任务，线程池也不会⻢上执⾏它们。
            b、当调⽤ execute() ⽅法添加⼀个任务时，线程池会做如下判断：

    1. 如果正在运⾏的线程数量⼩于 corePoolSize，那么⻢上创建线程运⾏这个任务；
    2. 如果正在运⾏的线程数量⼤于或等于 corePoolSize，那么将这个任务放⼊队列；
    3. 如果这时候队列满了，⽽且正在运⾏的线程数量⼩于 maximumPoolSize，那么还是要创建⾮核⼼线程⽴刻运⾏这个任务；
    4. 如果队列满了，⽽且正在运⾏的线程数量⼤于或等于 maximumPoolSize，那么线程池会抛出异常RejectExecutionException。
         3、当⼀个线程完成任务时，它会从队列中取下⼀个任务来执⾏。
            4、当⼀个线程⽆事可做，超过⼀定的时间（keepAliveTime）时，线程池会判断，如果当前运⾏的线程数⼤于corePoolSize，那么这个线程就被停掉。所以线程池的所有任务完成后，它最终会收缩到 corePoolSize 的⼤⼩。

46.  java中加锁的⽅式有哪些,如何实现怎么个写法.
        1、java中有两种锁：⼀种是**⽅法锁**或者**对象锁**(在⾮静态⽅法或者代码块上加锁)，第⼆种是**类锁**(在静态⽅法或者class上加锁)；
        2、注意：其他线程可以访问未加锁的⽅法和代码；synchronized同时修饰静态⽅法和实例⽅法，但是运⾏结果是交替进⾏的，这证明了类锁和对象锁是两个不⼀样的锁，控制着不同的区域，它们是互不⼲扰的。

47. 如何保证数据不丢失：
    1、使⽤消息队列，消息持久化；
    2、添加标志位：未处理 0，处理中 1，已处理 2。定时处理。

48. **jdk8中对ConcurrentHashmap的改进**

    1. Java 7为实现并⾏访问，引⼊了Segment这⼀结构，实现了分段锁，理论上最⼤并发度与Segment个数相等。
    2. Java 8为进⼀步提⾼并发性，摒弃了分段锁的⽅案，⽽是直接使⽤⼀个⼤的数组。同时为了提⾼哈希碰撞下的寻址性能，Java 8在链表⻓度超过⼀定阈值（8）时将链表（寻址时间复杂度为O(N)）转换为红⿊树（寻址时间复杂度为O(long(N))）

49. stop() 和  suspend() 方法为何不推荐使用？ 

    **反对使用  stop()，是因为它不安全。它会解除由线程获取的所有锁定**，而且如果对象处于一种不连贯状态，那么其他线程能在那种状态下检查和修改它们。结果很难检查出真正的问题所在。 
    **suspend() 方法容易发生死锁。**调用  suspend() 的时候，目标线程会停下来，**但却仍然持有在这之前获得的锁定。**此时，其他任何线程都不能访问锁定的资源，除非被  "挂起" 的线程恢复运行。对任何线程来说，如果它们想恢复目标线程，同时又试图使用任何一个锁定的资源，就会造成死锁。所以不应该使用  suspend()，而应在自己的  Thread 类中置入一个标志，指出线程应该活动还是挂起。若标志指出线程应该挂起，便用  wait() 命其进入等待状态。若标志指出线程应当恢复，则用一个  notify() 重新启动线程。 

50.  当一个线程进入一个对象的一个  synchronized 方法后，其它线程是否可进入此对象的其它方法?

    a. 其他方法前是否加了  synchronized 关键字，如果没加，则能。 
    b. 如果这个方法内部调用了  wait，则可以进入其他  synchronized 方法。 
    c. 如果其他个方法都加了  synchronized 关键字，并且内部没有调用  wait，则不能。 
    d. 如果其他方法是  static，它用的同步锁是当前类的字节码，与非静态的方法不能同步，因为非静态的方法用的是  this。 

51. volatile 类型变量提供什么保证？能使得一个非原子操作变成原子操作吗？ 

    volatile 提供  happens-before 的保证，确保一个线程的修改能对其他线程是可见的。  

    在  Java 中除了  long 和  double 之外的所有基本类型的读和赋值，都是原子性操作。而  64 位的  long 和  double 变量由于会被  JVM 当作两个分离的  32 位来进行操作，所以不具有原子性，会产生字撕裂问题。但是当你定义  long 或  double 变量时，如果使用  volatile 关键字，就会获到（简单的赋值与返回操作的）原子性。 

52. .多线程同步有哪几种方法？

    Synchronized 关键字，Lock 锁实现，分布式锁等。

53. CyclicBarrier 和 CountDownLatch 的区别？

    两个看上去有点像的类，都在 java.util.concurrent 下，都可以用来表示代码运行到某个点上，二者的区别在于：
    1) CyclicBarrier 的某个线程运行到某个点上之后，该线程即停止运行，直到所有的线程都到达了这个点，所有线程才重新运行；CountDownLatch 则不是，某线程运行到某个点上之后，只是给某个数值-1而已，该线程继续运行

    2) CyclicBarrier 只能唤起一个任务，CountDownLatch 可以唤起多个任务
    3) CyclicBarrier 可 重 用 ， CountDownLatch 不 可 重 用 ， 计 数 值 为 0 该CountDownLatch就不可再用了

54. 、什么是活锁、饥饿、无锁、死锁？

    死锁、活锁、饥饿是关于多线程是否活跃出现的运行阻塞障碍问题，如果线程出现了这三种情况，即线程不再活跃，不能再正常地执行下去了。
    1) **死锁**
    死锁是多线程中最差的一种情况，多个线程相互占用对方的资源的锁，而又相互等对方释放锁，此时若无外力干预，这些线程则一直处理阻塞的假死状态，形成死锁。
    举个例子，A 同学抢了 B 同学的钢笔，B 同学抢了 A 同学的书，两个人都相互占用对方的东西，都在让对方先还给自己自己再还，这样一直争执下去等待对方还而又得不到解决，老师知道此事后就让他们相互还给对方，这样在外力的干预下他们才解决，当然这只是个例子没有老师他们也能很好解决，计算机不像人如果发现这种情况没有外力干预还是会一直阻塞下去的。
    2) **活锁**
    活锁这个概念大家应该很少有人听说或理解它的概念，而在多线程中这确实存在。活锁恰恰与死锁相反，死锁是大家都拿不到资源都占用着对方的资源，而活锁是拿到资源却又相互释放不执行。当多线程中出现了相互谦让，都主动将资源释放给别的线程使用，这样这个资源在多个线程之间跳动而又得不到执行，这就是活锁。
    3) **饥饿**
    我们知道多线程执行中有线程优先级这个东西，优先级高的线程能够插队并优先执行，这样如果**优先级高的线程一直抢占优先级低线程的资源，导致低优先级线程无法得到执行**，这就是饥饿。当然还有一种饥饿的情况，一个线程一直占着一个资源不放而导致其他线程得不到执行，与死锁不同的是饥饿在以后一段时间内还是能够得到执行的，如那个占用资源的线程结束了并释放了资源。
    4) **无锁**
    无锁，即没有对资源进行锁定，即所有的线程都能访问并修改同一个资源，但同时只有一个线程能修改成功。无锁典型的特点就是一个修改操作在一个循环内进行，线程会不断的尝试修改共享资源，如果没有冲突就修改成功并退出否则就会继续下一次循环尝试。所以，如果有多个线程修改同一个值必定会有一个线程能修改成功，而其他修改失败的线程会不断重试直到修改成功。之前的文章我介绍过 JDK 的CAS原理及应用即是无锁的实现。可以看出，无锁是一种非常良好的设计，它不会出现线程出现的跳跃性问题，锁使
    用不当肯定会出现系统性能问题，虽然无锁无法全面代替有锁，但无锁在某些场合下是非常高效的。

55. 线程 yield()方法有什么用？

    Yield 方法可以暂停当前正在执行的线程对象，让其它有相同优先级的线程执行。它是一个静态方法而且只保证当前线程放弃 CPU 占用而不能保证使其它线程一定能占用CPU，执行yield()的线程有可能在进入到暂停状态后马上又被执行。

56. Thread.sleep(0)的作用是什么？

    由于 Java 采用抢占式的线程调度算法，因此可能会出现某条线程常常获取到 CPU控制权的情况，为了让某些优先级比较低的线程也能获取到 CPU 控制权，可以使用 Thread.sleep(0)手动触发一次操作系统分配时间片的操作，这也是平衡 CPU控制权的一种操作。

57. Java 内存模型是什么，哪些区域是线程共享的，哪些是不共享的？

    我们知道的 JVM 内存区域有：堆和栈，这是一种泛的分法，也是按运行时区域的一种分法，堆是所有线程共享的一块区域，而栈是线程隔离的，每个线程互不共享。
    线程不共享区域每个线程的数据区域包括程序计数器、虚拟机栈和本地方法栈，它们都是在新线程创建时才创建的。
    程序计数器（Program Counter Rerister）
    程序计数器区域一块内存较小的区域，它用于存储线程的每个执行指令，每个线程都有自己的程序计数器，此区域不会有内存溢出的情况。
    **虚拟机栈（VM Stack）**
    虚拟机栈描述的是 Java 方法执行的内存模型，每个方法被执行的时候都会同时创建一个栈帧（Stack Frame）用于存储局部变量表、操作数栈、动态链接、方法出口等信息。每一个方法被调用直至执行完成的过程就对应着一个栈帧在虚拟机栈中从入栈到出栈的过程。
    **本地方法栈（Native Method Stack）**
    本地方法栈用于支持本地方法（native标识的方法，即非 Java 语言实现的方法）。虚拟机栈和本地方法栈，当线程请求分配的栈容量超过 JVM 允许的最大容量时抛出StackOverflowError异常。
    线程共享区域
    线程共享区域包含：堆和方法区。
    **堆（Heap）**
    堆是最常处理的区域，它存储在 JVM 启动时创建的数组和对象，JVM 垃圾收集也主要是在堆上面工作。如果实际所需的堆超过了自动内存管理系统能提供的最大容量时抛出OutOfMemoryError 异常。
    **方法区（Method Area）**
    方法区是可供各条线程共享的运行时内存区域。存储了每一个类的结构信息，例如运行时常量池（Runtime Constant Pool）、字段和方法数据、构造函数和普通方法的字节码内容、还包括一些在类、实例、接口初始化时用到的特殊方法。当创建类和接口时，如果构造运行时常量池所需的内存空间超过了方法区所能提供的最大内存空间后就会抛出 OutOfMemoryError
    运行时常量池（Runtime Constant Pool）
    运行时常量池是方法区的一部分，每一个运行时常量池都分配在 JVM 的方法区中，在类和接口被加载到 JVM 后，对应的运行时常量池就被创建。运行时常量池是每一个类或接口的常量池（Constant_Pool）的运行时表现形式，它包括了若干种常量：
    编译器可知的数值字面量到必须运行期解析后才能获得的方法或字段的引用。如果方法区的内存空间不能满足内存分配请求，那 Java 虚 拟 机 将 抛 出 一 个OutOfMemoryError 异常。栈包含 Frames，当调用方法时，Frame 被推送到堆栈。一个 Frame包含局部变量数组、操作数栈、常量池引用。
